# üì∏ T√©cnicas de Procesamiento de Im√°genes - Visi√≥n por Computadora I

## üìã √çndice de Contenidos

- [Clase 1: Fundamentos de OpenCV e Im√°genes](#clase-1-fundamentos-de-opencv-e-im√°genes)
- [Clase 2: Operadores de P√≠xel y Histogramas](#clase-2-operadores-de-p√≠xel-y-histogramas)
- [Clase 3: Filtros y Transformadas](#clase-3-filtros-y-transformadas)
- [Clase 4: Detecci√≥n de Patrones y Caracter√≠sticas](#clase-4-detecci√≥n-de-patrones-y-caracter√≠sticas)
- [Clase 5: Descriptores de Caracter√≠sticas](#clase-5-descriptores-de-caracter√≠sticas)
- [Clase 6: Segmentaci√≥n y Tracking](#clase-6-segmentaci√≥n-y-tracking)
- [Clase 7: Procesamiento de Video y Flujo √ìptico](#clase-7-procesamiento-de-video-y-flujo-√≥ptico)

---

## üîß Clase 1: Fundamentos de OpenCV e Im√°genes

### **T√©cnicas Principales:**

#### 1. **Carga y Visualizaci√≥n de Im√°genes**
- **Para qu√© sirve**: Cargar im√°genes desde archivos y mostrarlas en pantalla
- **Funciones clave**: `cv.imread()`, `cv.imshow()`, `plt.imshow()`
- **Ejemplo**:
```python
img = cv.imread('imagen.jpg', cv.IMREAD_GRAYSCALE)
plt.imshow(img, cmap='gray')
plt.show()
```

#### 2. **Manipulaci√≥n de Canales de Color**
- **Para qu√© sirve**: Separar y trabajar con los diferentes canales RGB/BGR
- **Funciones clave**: `cv.split()`, `cv.merge()`
- **Ejemplo**:
```python
b, g, r = cv.split(img_color)  # Separar canales
img_merged = cv.merge([b, g, r])  # Reunir canales
```

#### 3. **Operaciones B√°sicas con P√≠xeles**
- **Para qu√© sirve**: Acceder y modificar valores individuales de p√≠xeles
- **Ejemplo**:
```python
pixel_value = img[100, 150]  # Obtener valor de p√≠xel
img[100, 150] = 255  # Modificar p√≠xel
```

#### 4. **Conversi√≥n de Espacios de Color**
- **Para qu√© sirve**: Convertir entre diferentes representaciones de color (BGR, RGB, HSV, etc.)
- **Funciones clave**: `cv.cvtColor()`
- **Ejemplo**:
```python
img_hsv = cv.cvtColor(img_bgr, cv.COLOR_BGR2HSV)
img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
```

#### 5. **Segmentaci√≥n por Color**
- **Para qu√© sirve**: Separar objetos de una imagen bas√°ndose en rangos de color
- **Funciones clave**: `cv.inRange()`, `cv.bitwise_and()`
- **Ejemplo**:
```python
# Detectar objetos verdes en HSV
lower_green = np.array([40, 50, 50])
upper_green = np.array([80, 255, 255])
mask = cv.inRange(img_hsv, lower_green, upper_green)
result = cv.bitwise_and(img, img, mask=mask)
```

#### 6. **Operaciones L√≥gicas**
- **Para qu√© sirve**: Combinar im√°genes usando operaciones booleanas
- **Funciones clave**: `cv.bitwise_and()`, `cv.bitwise_or()`, `cv.bitwise_not()`
- **Ejemplo**:
```python
result = cv.bitwise_and(img1, img2)  # AND entre dos im√°genes
```

---

## üìä Clase 2: Operadores de P√≠xel y Histogramas

### **T√©cnicas Principales:**

#### 1. **Control de Brillo**
- **Para qu√© sirve**: Aumentar o disminuir la luminosidad general de la imagen
- **F√≥rmula**: `nueva_imagen = imagen_original + (255 * porcentaje_brillo / 100)`
- **Ejemplo**:
```python
def change_brightness(img, bright_percent):
    img_new = img + (255 * bright_percent / 100)
    return np.clip(img_new, 0, 255).astype('uint8')

img_bright = change_brightness(img, 30)  # +30% brillo
```

#### 2. **Control de Contraste**
- **Para qu√© sirve**: Aumentar o disminuir la diferencia entre tonos claros y oscuros
- **F√≥rmula**: `nueva_imagen = (1 + contraste/100) * imagen_original`
- **Ejemplo**:
```python
def change_contrast(img, contrast_percent):
    img_new = (1 + contrast_percent / 100) * img
    return np.clip(img_new, 0, 255).astype('uint8')

img_contrast = change_contrast(img, 50)  # +50% contraste
```

#### 3. **Correcci√≥n Gamma**
- **Para qu√© sirve**: Ajustar la luminancia no linealmente para corregir el brillo
- **Cu√°ndo usar**: Gamma < 1 para aclarar, Gamma > 1 para oscurecer
- **Ejemplo**:
```python
gamma = 0.7
img_gamma = np.power(img.astype('float32') / 255.0, 1.0/gamma)
img_gamma = (img_gamma * 255).astype('uint8')
```

#### 4. **An√°lisis de Histogramas**
- **Para qu√© sirve**: Analizar la distribuci√≥n de intensidades en la imagen
- **Funciones clave**: `cv.calcHist()`, `np.histogram()`
- **Ejemplo**:
```python
hist = cv.calcHist([img], [0], None, [256], [0, 256])
plt.plot(hist)
plt.show()
```

#### 5. **Histogramas 2D**
- **Para qu√© sirve**: Analizar la relaci√≥n entre dos canales de color
- **Ejemplo**:
```python
img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)
hist_2d = cv.calcHist([img_hsv], [0, 2], None, [180, 256], [0, 180, 0, 255])
plt.imshow(hist_2d, cmap='jet')
```

#### 6. **Ecualizaci√≥n de Histograma**
- **Para qu√© sirve**: Mejorar el contraste distribuyendo mejor las intensidades
- **Funciones clave**: `cv.equalizeHist()`
- **Ejemplo**:
```python
img_eq = cv.equalizeHist(img_gray)
```

#### 7. **Binarizaci√≥n (Thresholding)**
- **Para qu√© sirve**: Convertir im√°genes a escala de grises en im√°genes binarias
- **Tipos**: Fijo, Otsu, Adaptativo
- **Ejemplo**:
```python
# Umbral fijo
ret, thresh_fixed = cv.threshold(img, 127, 255, cv.THRESH_BINARY)

# Umbral Otsu (autom√°tico)
ret, thresh_otsu = cv.threshold(img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

# Umbral adaptativo
thresh_adaptive = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_MEAN_C, 
                                       cv.THRESH_BINARY, 11, 2)
```

---

## üîç Clase 3: Filtros y Transformadas

### **T√©cnicas Principales:**

#### 1. **Filtro Gaussiano**
- **Para qu√© sirve**: Suavizar la imagen reduciendo el ruido
- **Funciones clave**: `cv.GaussianBlur()`, `cv.getGaussianKernel()`
- **Ejemplo**:
```python
img_blur = cv.GaussianBlur(img, (15, 15), sigmaX=5, sigmaY=5)
```

#### 2. **Filtros de Media y Mediana**
- **Para qu√© sirve**: 
  - **Media**: Suavizado general
  - **Mediana**: Eliminar ruido sal y pimienta espec√≠ficamente
- **Ejemplo**:
```python
img_mean = cv.blur(img, (5, 5))  # Filtro de media
img_median = cv.medianBlur(img, 5)  # Filtro de mediana
```

#### 3. **Diferencia de Gaussianas (DoG)**
- **Para qu√© sirve**: Detectar bordes y caracter√≠sticas de diferentes escalas
- **Ejemplo**:
```python
blur1 = cv.GaussianBlur(img, (5, 5), 1.0)
blur2 = cv.GaussianBlur(img, (5, 5), 2.0)
dog = blur1 - blur2
```

#### 4. **Detecci√≥n de Bordes con Canny**
- **Para qu√© sirve**: Detectar contornos y bordes con alta precisi√≥n
- **Funciones clave**: `cv.Canny()`
- **Ejemplo**:
```python
edges = cv.Canny(img, threshold1=100, threshold2=200, apertureSize=3)
```

#### 5. **Operadores de Gradiente (Sobel, Laplaciano)**
- **Para qu√© sirve**: Detectar cambios de intensidad en direcciones espec√≠ficas
- **Ejemplo**:
```python
# Sobel en X e Y
sobelx = cv.Sobel(img, cv.CV_64F, 1, 0, ksize=3)
sobely = cv.Sobel(img, cv.CV_64F, 0, 1, ksize=3)

# Laplaciano
laplacian = cv.Laplacian(img, cv.CV_64F)
```

#### 6. **Transformada de Fourier**
- **Para qu√© sirve**: An√°lisis frecuencial de la imagen, filtrado en dominio de frecuencia
- **Ejemplo**:
```python
# FFT
f_transform = np.fft.fft2(img)
f_shift = np.fft.fftshift(f_transform)
magnitude = np.log(np.abs(f_shift) + 1)

# Filtros pasa-bajos y pasa-altos en frecuencia
def create_low_pass_filter(h, w, radius):
    center = (h//2, w//2)
    Y, X = np.ogrid[:h, :w]
    dist = np.sqrt((X - center[1])**2 + (Y - center[0])**2)
    return (dist <= radius).astype(float)
```

#### 7. **Filtros Bilaterales**
- **Para qu√© sirve**: Suavizar manteniendo bordes n√≠tidos
- **Funciones clave**: `cv.bilateralFilter()`
- **Ejemplo**:
```python
img_bilateral = cv.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)
```

---

## üéØ Clase 4: Detecci√≥n de Patrones y Caracter√≠sticas

### **T√©cnicas Principales:**

#### 1. **Template Matching (B√∫squeda de Patrones)**
- **Para qu√© sirve**: Encontrar un patr√≥n espec√≠fico dentro de una imagen m√°s grande
- **M√©todos**: TM_CCOEFF, TM_CCOEFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_SQDIFF, TM_SQDIFF_NORMED
- **Ejemplo**:
```python
template = cv.imread('patron.png', 0)
img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

# B√∫squeda de un solo objeto
res = cv.matchTemplate(img_gray, template, cv.TM_CCOEFF_NORMED)
min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)

# B√∫squeda de m√∫ltiples objetos
threshold = 0.8
locations = np.where(res >= threshold)
for pt in zip(*locations[::-1]):
    cv.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)
```

#### 2. **Transformada de Hough para L√≠neas**
- **Para qu√© sirve**: Detectar l√≠neas rectas en im√°genes
- **Tipos**: Est√°ndar y Probabil√≠stica
- **Ejemplo**:
```python
# Transformada de Hough est√°ndar
edges = cv.Canny(img_gray, 50, 150)
lines = cv.HoughLines(edges, rho=1, theta=np.pi/180, threshold=200)

# Transformada de Hough probabil√≠stica
lines_p = cv.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=50,
                         minLineLength=50, maxLineGap=10)
```

#### 3. **Transformada de Hough para C√≠rculos**
- **Para qu√© sirve**: Detectar c√≠rculos en im√°genes
- **Ejemplo**:
```python
img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
img_blur = cv.medianBlur(img_gray, 5)

circles = cv.HoughCircles(img_blur, cv.HOUGH_GRADIENT, dp=1, minDist=20,
                          param1=50, param2=30, minRadius=0, maxRadius=0)

for circle in circles[0, :]:
    cv.circle(img, (circle[0], circle[1]), circle[2], (0, 255, 0), 2)
    cv.circle(img, (circle[0], circle[1]), 2, (0, 0, 255), 3)
```

#### 4. **Detecci√≥n de Esquinas con Harris**
- **Para qu√© sirve**: Encontrar puntos de inter√©s (esquinas) en la imagen
- **Ejemplo**:
```python
img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
img_gray = np.float32(img_gray)

# Detector de Harris
dst = cv.cornerHarris(img_gray, blockSize=2, ksize=3, k=0.04)
dst = cv.dilate(dst, None)

# Marcar esquinas
img[dst > 0.01 * dst.max()] = [0, 0, 255]
```

#### 5. **Detector de Esquinas Shi-Tomasi**
- **Para qu√© sirve**: Alternativa mejorada al detector de Harris
- **Ejemplo**:
```python
corners = cv.goodFeaturesToTrack(img_gray, maxCorners=100, qualityLevel=0.01,
                                 minDistance=10, blockSize=3)

for corner in corners:
    x, y = corner.ravel()
    cv.circle(img, (x, y), 3, 255, -1)
```

#### 6. **Refinamiento Sub-p√≠xel de Esquinas**
- **Para qu√© sirve**: Mejorar la precisi√≥n de la ubicaci√≥n de las esquinas
- **Ejemplo**:
```python
criteria = (cv.TERM_CRITERIA_MAX_ITER + cv.TERM_CRITERIA_EPS, 100, 0.001)
corners_refined = cv.cornerSubPix(img_gray, np.float32(corners), 
                                  winSize=(5, 5), zeroZone=(-1, -1), 
                                  criteria=criteria)
```

#### 7. **Pir√°mides Gaussianas y Laplacianas**
- **Para qu√© sirve**: 
  - **Gaussianas**: An√°lisis multi-escala, reducci√≥n de resoluci√≥n
  - **Laplacianas**: Compresi√≥n, fusi√≥n de im√°genes
- **Ejemplo**:
```python
# Pir√°mide Gaussiana
def gaussian_pyramid(img, levels):
    pyramid = [img]
    for i in range(levels):
        img = cv.pyrDown(img)
        pyramid.append(img)
    return pyramid

# Pir√°mide Laplaciana
def laplacian_pyramid(gaussian_pyramid):
    laplacian_pyramid = []
    for i in range(len(gaussian_pyramid)-1):
        size = (gaussian_pyramid[i].shape[1], gaussian_pyramid[i].shape[0])
        expanded = cv.pyrUp(gaussian_pyramid[i+1], dstsize=size)
        laplacian = cv.subtract(gaussian_pyramid[i], expanded)
        laplacian_pyramid.append(laplacian)
    laplacian_pyramid.append(gaussian_pyramid[-1])
    return laplacian_pyramid

# Fusi√≥n de im√°genes usando pir√°mides
def blend_images(img1, img2, mask, levels):
    # Crear pir√°mides para ambas im√°genes y la m√°scara
    gauss_pyr1 = gaussian_pyramid(img1, levels)
    gauss_pyr2 = gaussian_pyramid(img2, levels)
    mask_pyr = gaussian_pyramid(mask, levels)
    
    # Crear pir√°mides Laplacianas
    laplace_pyr1 = laplacian_pyramid(gauss_pyr1)
    laplace_pyr2 = laplacian_pyramid(gauss_pyr2)
    
    # Combinar usando la m√°scara
    blended_pyr = []
    for l1, l2, m in zip(laplace_pyr1, laplace_pyr2, mask_pyr):
        blended = l1 * m + l2 * (1.0 - m)
        blended_pyr.append(blended)
    
    return blended_pyr
```

---

## üîç Clase 5: Descriptores de Caracter√≠sticas

### **T√©cnicas Principales:**

#### 1. **SIFT (Scale-Invariant Feature Transform)**
- **Para qu√© sirve**: Detectar y describir caracter√≠sticas locales invariantes a escala y rotaci√≥n
- **Ventajas**: Muy robusto, invariante a escala, rotaci√≥n e iluminaci√≥n
- **Ejemplo**:
```python
sift = cv.xfeatures2d.SIFT_create()
keypoints, descriptors = sift.detectAndCompute(img_gray, None)

# Dibujar keypoints
img_sift = cv.drawKeypoints(img, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

print(f'Descriptores encontrados: {len(keypoints)}')
print(f'Dimensi√≥n de descriptores: {descriptors.shape}')
```

#### 2. **SURF (Speeded-Up Robust Features)**
- **Para qu√© sirve**: Versi√≥n m√°s r√°pida de SIFT con caracter√≠sticas similares
- **Ventajas**: Mayor velocidad que SIFT manteniendo robustez
- **Ejemplo**:
```python
surf = cv.xfeatures2d.SURF_create(hessianThreshold=400)
keypoints, descriptors = surf.detectAndCompute(img_gray, None)
img_surf = cv.drawKeypoints(img, keypoints, None)
```

#### 3. **ORB (Oriented FAST and Rotated BRIEF)**
- **Para qu√© sirve**: Alternativa r√°pida y libre de patentes a SIFT/SURF
- **Ventajas**: Muy r√°pido, libre de patentes, buenos resultados
- **Ejemplo**:
```python
orb = cv.ORB_create()
keypoints, descriptors = orb.detectAndCompute(img_gray, None)
img_orb = cv.drawKeypoints(img, keypoints, None, color=(0, 255, 0))
```

#### 4. **FAST (Features from Accelerated Segment Test)**
- **Para qu√© sirve**: Detecci√≥n r√°pida de esquinas
- **Ventajas**: Extremadamente r√°pido
- **Ejemplo**:
```python
fast = cv.FastFeatureDetector_create()
keypoints = fast.detect(img_gray, None)
img_fast = cv.drawKeypoints(img, keypoints, None, color=(255, 0, 0))
```

#### 5. **Matching de Caracter√≠sticas**
- **Para qu√© sirve**: Encontrar correspondencias entre caracter√≠sticas de dos im√°genes
- **M√©todos**: Brute Force, FLANN
- **Ejemplo**:
```python
# Brute Force Matcher
bf = cv.BFMatcher()
matches = bf.knnMatch(descriptors1, descriptors2, k=2)

# Filtro de Lowe para buenos matches
good_matches = []
for m, n in matches:
    if m.distance < 0.75 * n.distance:
        good_matches.append([m])

# Dibujar matches
img_matches = cv.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, flags=2)
```

#### 6. **RANSAC para Homograf√≠a**
- **Para qu√© sirve**: Estimar transformaciones geom√©tricas robustas eliminando outliers
- **Ejemplo**:
```python
# Extraer puntos de los matches
src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

# Calcular homograf√≠a con RANSAC
M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)

# Aplicar transformaci√≥n
h, w = img1.shape[:2]
pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)
dst = cv.perspectiveTransform(pts, M)
```

#### 7. **Creaci√≥n de Panoramas**
- **Para qu√© sirve**: Unir m√∫ltiples im√°genes para crear vistas panor√°micas
- **Ejemplo**:
```python
def create_panorama(img1, img2):
    # Detectar caracter√≠sticas
    sift = cv.xfeatures2d.SIFT_create()
    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)
    
    # Matching
    bf = cv.BFMatcher()
    matches = bf.knnMatch(des1, des2, k=2)
    
    # Filtrar matches
    good = []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            good.append(m)
    
    # Calcular homograf√≠a
    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)
    
    # Crear panorama
    result = cv.warpPerspective(img1, M, (img1.shape[1] + img2.shape[1], img1.shape[0]))
    result[0:img2.shape[0], 0:img2.shape[1]] = img2
    
    return result
```

---

## üé® Clase 6: Segmentaci√≥n y Tracking

### **T√©cnicas Principales:**

#### 1. **Segmentaci√≥n por K-Means**
- **Para qu√© sirve**: Agrupar p√≠xeles similares en color para segmentar regiones
- **Ejemplo**:
```python
# Reformatear imagen para K-means
features = img.reshape((-1, 3))
features = np.float32(features)

# Criterios y configuraci√≥n
criteria = (cv.TERM_CRITERIA_MAX_ITER + cv.TERM_CRITERIA_EPS, 10, 1.0)
K = 5

# Aplicar K-means
compact, labels, centers = cv.kmeans(features, K, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)

# Reconstruir imagen segmentada
centers = np.uint8(centers)
segmented_img = centers[labels.flatten()]
segmented_img = segmented_img.reshape(img.shape)
```

#### 2. **Algoritmo Watershed**
- **Para qu√© sirve**: Segmentaci√≥n basada en morfolog√≠a matem√°tica, √∫til para separar objetos unidos
- **Ejemplo**:
```python
# Preprocesamiento
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)

# Operaciones morfol√≥gicas
kernel = np.ones((3, 3), np.uint8)
opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=2)

# √Årea de fondo seguro
sure_bg = cv.dilate(opening, kernel, iterations=3)

# √Årea de primer plano seguro
dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)
ret, sure_fg = cv.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)

# Regi√≥n desconocida
sure_fg = np.uint8(sure_fg)
unknown = cv.subtract(sure_bg, sure_fg)

# Marcadores para watershed
ret, markers = cv.connectedComponents(sure_fg)
markers = markers + 1
markers[unknown == 255] = 0

# Aplicar watershed
markers = cv.watershed(img, markers)
img[markers == -1] = [255, 0, 0]  # Marcar fronteras en rojo
```

#### 3. **Mean Shift Clustering**
- **Para qu√© sirve**: Segmentaci√≥n autom√°tica sin especificar n√∫mero de clusters
- **Ejemplo**:
```python
# Aplicar Mean Shift
shifted = cv.pyrMeanShiftFiltering(img, sp=21, sr=51)

# Convertir a array plano para an√°lisis
flat_image = shifted.reshape((-1, 3))
flat_image = np.float32(flat_image)

# Aplicar K-means para obtener colores finales
criteria = (cv.TERM_CRITERIA_MAX_ITER + cv.TERM_CRITERIA_EPS, 20, 1.0)
compactness, labels, centers = cv.kmeans(flat_image, 8, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)
```

#### 4. **Mean Shift Tracking**
- **Para qu√© sirve**: Seguimiento de objetos basado en histogramas de color
- **Ejemplo**:
```python
# Configuraci√≥n inicial
cap = cv.VideoCapture('video.mp4')
ret, frame = cap.read()

# Definir ROI inicial
x, y, w, h = 300, 200, 100, 50
track_window = (x, y, w, h)

# Calcular histograma de la ROI
roi = frame[y:y+h, x:x+w]
hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)
mask = cv.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))
roi_hist = cv.calcHist([hsv_roi], [0], mask, [180], [0, 180])
cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)

# Criterios de terminaci√≥n
term_crit = (cv.TERM_CRITERIA_COUNT | cv.TERM_CRITERIA_EPS, 10, 1)

while True:
    ret, frame = cap.read()
    if ret:
        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)
        dst = cv.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)
        
        # Aplicar Mean Shift
        ret, track_window = cv.meanShift(dst, track_window, term_crit)
        
        # Dibujar ventana de seguimiento
        x, y, w, h = track_window
        img2 = cv.rectangle(frame, (x, y), (x+w, y+h), 255, 2)
        cv.imshow('Tracking', img2)
        
    if cv.waitKey(60) & 0xff == 27:
        break
```

#### 5. **CAMShift (Continuously Adaptive Mean Shift)**
- **Para qu√© sirve**: Extensi√≥n de Mean Shift que adapta el tama√±o de la ventana de seguimiento
- **Ejemplo**:
```python
# Similar al Mean Shift pero usando CAMShift
ret, track_window = cv.CamShift(dst, track_window, term_crit)

# CAMShift devuelve un rect√°ngulo rotado
pts = cv.boxPoints(ret)
pts = np.int0(pts)
img2 = cv.polylines(frame, [pts], True, 255, 2)
```

---

## üé¨ Clase 7: Procesamiento de Video y Flujo √ìptico

### **T√©cnicas Principales:**

#### 1. **Flujo √ìptico de Lucas-Kanade**
- **Para qu√© sirve**: Seguir caracter√≠sticas espec√≠ficas entre frames consecutivos
- **Ejemplo**:
```python
# Par√°metros para detecci√≥n de caracter√≠sticas
feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Par√°metros para Lucas-Kanade
lk_params = dict(winSize=(15, 15), maxLevel=2,
                 criteria=(cv.TERM_CRITERIA_COUNT | cv.TERM_CRITERIA_EPS, 10, 0.03))

# Capturar primer frame
cap = cv.VideoCapture('video.mp4')
ret, old_frame = cap.read()
old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)
p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Crear m√°scara para dibujar estelas
mask = np.zeros_like(old_frame)
colors = np.random.randint(0, 255, (100, 3))

while True:
    ret, frame = cap.read()
    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    
    # Calcular flujo √≥ptico
    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)
    
    # Seleccionar puntos buenos
    good_new = p1[st == 1]
    good_old = p0[st == 1]
    
    # Dibujar estelas
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), colors[i].tolist(), 2)
        frame = cv.circle(frame, (int(a), int(b)), 5, colors[i].tolist(), -1)
    
    img = cv.add(frame, mask)
    cv.imshow('Frame', img)
    
    # Actualizar frame anterior
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)
    
    if cv.waitKey(30) & 0xff == 27:
        break
```

#### 2. **Flujo √ìptico Denso (Farneback)**
- **Para qu√© sirve**: Calcular el movimiento de todos los p√≠xeles en la imagen
- **Ejemplo**:
```python
cap = cv.VideoCapture('video.mp4')
ret, frame1 = cap.read()
prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)
hsv = np.zeros_like(frame1)
hsv[..., 1] = 255

while True:
    ret, frame2 = cap.read()
    next_frame = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)
    
    # Calcular flujo √≥ptico denso
    flow = cv.calcOpticalFlowPyrLK(prvs, next_frame, None, None)
    
    # Convertir a coordenadas polares
    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])
    hsv[..., 0] = ang * 180 / np.pi / 2
    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)
    
    # Convertir a BGR para visualizaci√≥n
    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)
    cv.imshow('Frame', bgr)
    
    if cv.waitKey(30) & 0xff == ord('q'):
        break
    
    prvs = next_frame
```

#### 3. **Sustracci√≥n de Fondo (Background Subtraction)**
- **Para qu√© sirve**: Detectar objetos en movimiento separ√°ndolos del fondo est√°tico
- **Algoritmos**: MOG2, KNN

#### **Background Subtraction con MOG2**:
```python
# Crear el sustractor de fondo
back_sub = cv.createBackgroundSubtractorMOG2(detectShadows=True)

cap = cv.VideoCapture('video.mp4')

while True:
    ret, frame = cap.read()
    if ret:
        # Aplicar sustractor de fondo
        fg_mask = back_sub.apply(frame)
        
        # Mostrar frame original y m√°scara
        cv.imshow('Frame', frame)
        cv.imshow('FG Mask', fg_mask)
        
        # Encontrar contornos en la m√°scara
        contours, _ = cv.findContours(fg_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
        
        # Dibujar contornos de objetos detectados
        for contour in contours:
            if cv.contourArea(contour) > 500:  # Filtrar objetos peque√±os
                x, y, w, h = cv.boundingRect(contour)
                cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
        
        cv.imshow('Objects', frame)
        
    if cv.waitKey(30) & 0xff == 27:
        break
```

#### **Background Subtraction con KNN**:
```python
# KNN es m√°s robusto para escenas complejas
back_sub = cv.createBackgroundSubtractorKNN(detectShadows=True)

# El resto del c√≥digo es similar al MOG2
```

#### 4. **Detecci√≥n y Seguimiento de M√∫ltiples Objetos**
- **Para qu√© sirve**: Rastrear varios objetos simult√°neamente
- **Ejemplo**:
```python
# Usar background subtraction + tracking
class MultiObjectTracker:
    def __init__(self):
        self.back_sub = cv.createBackgroundSubtractorMOG2()
        self.trackers = []
    
    def detect_objects(self, frame):
        fg_mask = self.back_sub.apply(frame)
        contours, _ = cv.findContours(fg_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
        
        objects = []
        for contour in contours:
            if cv.contourArea(contour) > 1000:
                x, y, w, h = cv.boundingRect(contour)
                objects.append((x, y, w, h))
        
        return objects
    
    def update_trackers(self, frame, detected_objects):
        # Actualizar trackers existentes y crear nuevos
        for obj in detected_objects:
            # Crear nuevo tracker para cada objeto detectado
            tracker = cv.TrackerCSRT_create()
            tracker.init(frame, obj)
            self.trackers.append(tracker)
```

#### 5. **An√°lisis de Movimiento y Actividad**
- **Para qu√© sirve**: Detectar patrones de movimiento, √°reas de alta actividad
- **Ejemplo**:
```python
def motion_analysis(video_path):
    cap = cv.VideoCapture(video_path)
    
    # Acumulador para mapas de movimiento
    motion_history = None
    
    ret, frame1 = cap.read()
    prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)
    
    while True:
        ret, frame2 = cap.read()
        if not ret:
            break
            
        next_frame = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)
        
        # Calcular diferencia entre frames
        diff = cv.absdiff(prvs, next_frame)
        
        # Acumular movimiento
        if motion_history is None:
            motion_history = np.zeros_like(diff, dtype=np.float32)
        
        motion_history += diff.astype(np.float32)
        
        # Normalizar y mostrar mapa de calor
        motion_normalized = cv.normalize(motion_history, None, 0, 255, cv.NORM_MINMAX)
        motion_heatmap = cv.applyColorMap(motion_normalized.astype(np.uint8), cv.COLORMAP_JET)
        
        cv.imshow('Motion Heatmap', motion_heatmap)
        
        prvs = next_frame
        
        if cv.waitKey(30) & 0xff == 27:
            break
    
    return motion_history
```

---

## üìö Resumen de Aplicaciones por Clase

### **üéØ Aplicaciones Principales por T√©cnica:**

| **Clase** | **T√©cnicas Principales** | **Aplicaciones Reales** |
|-----------|--------------------------|--------------------------|
| **1** | Manipulaci√≥n b√°sica, espacios de color | Preprocesamiento, segmentaci√≥n por color, interfaces de usuario |
| **2** | Ajustes de imagen, histogramas, binarizaci√≥n | Mejora de calidad, an√°lisis m√©dico, OCR, visi√≥n nocturna |
| **3** | Filtros, detecci√≥n de bordes, Fourier | Reducci√≥n de ruido, an√°lisis de texturas, compresi√≥n de im√°genes |
| **4** | Template matching, Hough, esquinas | Reconocimiento de objetos, detecci√≥n de formas, calibraci√≥n de c√°maras |
| **5** | Descriptores robustos, matching | Panoramas, realidad aumentada, navegaci√≥n de robots |
| **6** | Segmentaci√≥n, tracking | An√°lisis m√©dico, seguimiento de objetos, interfaces gestuales |
| **7** | Procesamiento de video, flujo √≥ptico | Videovigilancia, an√°lisis de tr√°fico, deportes, cinematograf√≠a |

---

## üîß Herramientas y Librer√≠as Utilizadas

- **OpenCV (cv2)**: Librer√≠a principal para procesamiento de im√°genes y visi√≥n por computadora
- **NumPy**: Operaciones matriciales y num√©ricas eficientes
- **Matplotlib**: Visualizaci√≥n de im√°genes, gr√°ficos e histogramas
- **Scikit-image**: Algoritmos adicionales de procesamiento de im√°genes
- **Supervision**: Herramientas de visualizaci√≥n avanzadas

---

## üìñ Recursos Adicionales

Para profundizar en cada t√©cnica, consulta:
- [Documentaci√≥n oficial de OpenCV](https://docs.opencv.org/)
- [Tutoriales de OpenCV-Python](https://opencv-python-tutroials.readthedocs.io/)
- Papers acad√©micos en la carpeta `Articulos/`
- Diapositivas del curso en `Diapositivas/`

---

*Este README fue creado como referencia completa de todas las t√©cnicas de procesamiento de im√°genes vistas en el curso de Visi√≥n por Computadora I.*
